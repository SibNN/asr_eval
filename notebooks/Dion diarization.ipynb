{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import cast, Any\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pisets import load_sound # type: ignore\n",
    "import gigaam\n",
    "from gigaam.model import GigaAMASR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from asr_eval.models.gigaam_wrapper import transcribe_with_gigaam_ctc, FREQ, encode\n",
    "from asr_eval.ctc.forced_alignment import forced_alignment\n",
    "from asr_eval.ctc.chunking import chunked_ctc_prediction, average_logp_windows\n",
    "from asr_eval.utils.serializing import save_to_json, load_from_json\n",
    "from asr_eval.utils.misc import groupby_into_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gigaam_log_probs(\n",
    "    waveform: npt.NDArray[np.floating[Any]], model: GigaAMASR\n",
    ") -> npt.NDArray[np.floating[Any]]:\n",
    "    return average_logp_windows(chunked_ctc_prediction(\n",
    "        waveform=waveform,\n",
    "        ctc_model=lambda waveform: transcribe_with_gigaam_ctc(model, [waveform])[0].log_probs,\n",
    "        model_tick_size_sec=1 / FREQ,\n",
    "        segment_size_sec=20,\n",
    "        segment_shift_sec=6,\n",
    "        sampling_rate=16_000,\n",
    "    ))\n",
    "\n",
    "def filter_encodable_tokens(text: str, model: GigaAMASR) -> str:\n",
    "    assert model.decoding.tokenizer.charwise\n",
    "    text = text.lower().replace('ё', 'е').replace('-', ' ')\n",
    "    return ''.join(char for char in text if char in model.decoding.tokenizer.vocab)\n",
    "\n",
    "@dataclass\n",
    "class DionSegment:\n",
    "    approx_start_time: float\n",
    "    speaker: str | list[str]\n",
    "    text: str\n",
    "    text_start_pos: int\n",
    "    text_end_pos: int\n",
    "    \n",
    "def get_dion_segments(text_path: Path, model: GigaAMASR) -> tuple[list[DionSegment], str]:\n",
    "    joined_text = ''\n",
    "    segments: list[DionSegment] = []\n",
    "    for record in text_path.read_text(encoding='utf-8-sig').split('\\n\\n'):\n",
    "        try:\n",
    "            start_time_str, speaker, _, text = record.split('\\n')\n",
    "        except ValueError:\n",
    "            start_time_str, speaker1, speaker2, _, text = record.split('\\n')\n",
    "            speaker = [speaker1, speaker2]\n",
    "        \n",
    "        text = text[2:].strip()  # skip \"- \" prefix in the file\n",
    "        text = filter_encodable_tokens(text, model)\n",
    "        \n",
    "        try:\n",
    "            start_time = datetime.strptime(start_time_str, '%H:%M:%S') - datetime(1900, 1, 1)\n",
    "        except ValueError:\n",
    "            start_time = datetime.strptime(start_time_str, '%M:%S') - datetime(1900, 1, 1)\n",
    "        \n",
    "        if len(joined_text):\n",
    "            joined_text += ' '\n",
    "        joined_text += text\n",
    "        \n",
    "        segments.append(DionSegment(\n",
    "            approx_start_time=start_time.total_seconds() - 1.5,  # most often Dion timings are shifted forward by 1.5 sec\n",
    "            speaker=speaker,\n",
    "            text=text,\n",
    "            text_start_pos=len(joined_text) - len(text),\n",
    "            text_end_pos=len(joined_text),\n",
    "        ))\n",
    "    \n",
    "    return segments, joined_text\n",
    "    \n",
    "@dataclass\n",
    "class TimedWord:\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    text: str\n",
    "    \n",
    "@dataclass\n",
    "class AlignedDionTimedWord:\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    speaker: str | list[str]\n",
    "    text: str\n",
    "    delta: float\n",
    "\n",
    "def get_gigaam_argmax_timed_words(\n",
    "    log_probs: npt.NDArray[np.floating[Any]],\n",
    "    model: GigaAMASR, \n",
    ") -> list[TimedWord]:\n",
    "    idx_per_frame = log_probs.argmax(axis=1)\n",
    "    spans = [\n",
    "        (token_id, start, end)\n",
    "        for token_id, start, end in groupby_into_spans(idx_per_frame.tolist())\n",
    "        if token_id != model.decoding.blank_id\n",
    "    ]\n",
    "    text = ''.join(model.decoding.tokenizer.vocab[token_id] for token_id, _start, _end in spans)\n",
    "\n",
    "    words: list[TimedWord] = []\n",
    "    for match in re.finditer(r'\\w+', text):\n",
    "        _, start, _ = spans[match.start()]\n",
    "        _, _, end = spans[match.end() - 1]\n",
    "        words.append(TimedWord(\n",
    "            start_time=start / FREQ,\n",
    "            end_time=end / FREQ,\n",
    "            text=match.group(),\n",
    "        ))\n",
    "    \n",
    "    return words\n",
    "\n",
    "def do_forced_alignment(\n",
    "    log_probs: npt.NDArray[np.floating[Any]],\n",
    "    model: GigaAMASR,\n",
    "    joined_text: str,\n",
    "    segments: list[DionSegment],\n",
    ") -> list[AlignedDionTimedWord]:\n",
    "    _idx_per_frame, _scores_per_frame, true_tokens_pos = forced_alignment(\n",
    "        log_probs=log_probs,\n",
    "        true_tokens=encode(model, joined_text),\n",
    "        blank_id=model.decoding.blank_id,\n",
    "    )\n",
    "\n",
    "    timed_words: list[AlignedDionTimedWord] = []\n",
    "    for segment in segments:\n",
    "        \n",
    "        start_frame, _ = true_tokens_pos[segment.text_start_pos]\n",
    "        delta = start_frame / FREQ - segment.approx_start_time\n",
    "        \n",
    "        for match in re.finditer(r'\\w+', segment.text):\n",
    "            start_frame, _ = true_tokens_pos[segment.text_start_pos + match.start()]\n",
    "            _, end_frame = true_tokens_pos[segment.text_start_pos + match.end() - 1]\n",
    "            timed_words.append(AlignedDionTimedWord(\n",
    "                start_time=start_frame / FREQ,\n",
    "                end_time=end_frame / FREQ,\n",
    "                speaker=segment.speaker,\n",
    "                text=match.group(),\n",
    "                delta=round(delta, 3), # usually values like 1.5000000001 or 1.4999999999\n",
    "            ))\n",
    "    \n",
    "    return timed_words\n",
    "\n",
    "def draw_time_deltas(timed_words: list[AlignedDionTimedWord]):\n",
    "    plt.figure(figsize=(10, 2)) # type: ignore\n",
    "    deltas = [x.delta for x in timed_words]\n",
    "    plt.title( # type: ignore\n",
    "        f'Match between GigaAM forced alignment and Dion timings:\\nmedian delta'\n",
    "        f' {np.median(deltas):.2f}, min delta {min(deltas):.2f}, max delta {max(deltas):.2f}'\n",
    "    )\n",
    "    plt.plot(deltas) # type: ignore\n",
    "    plt.axhline(0, color='lightgray', zorder=0) # type: ignore\n",
    "    plt.show() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cast(GigaAMASR, gigaam.load_model('ctc', device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_path in Path('/asr_datasets/dion/').glob('*.mp4'):\n",
    "    print(video_path)\n",
    "    \n",
    "    text_path = video_path.with_suffix('.txt')\n",
    "    output_path = video_path.with_suffix('.json')\n",
    "    \n",
    "    if output_path.exists():\n",
    "        continue\n",
    "\n",
    "    if video_path.name in (  # multispeaker dion transcriptions\n",
    "        'kondrashuk_2025-06-25T12_12_07+03_00.mp4',  # too long for CTC\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    # get conference transcription from Dion\n",
    "    dion_segments, joined_text = get_dion_segments(text_path, model)\n",
    "\n",
    "    # get log probs from GigaAM\n",
    "    waveform = load_sound(video_path)\n",
    "    log_probs = get_gigaam_log_probs(waveform, model)\n",
    "    \n",
    "    gigaam_timed_words = get_gigaam_argmax_timed_words(log_probs, model)\n",
    "\n",
    "    # align both\n",
    "    aligned_timed_words = do_forced_alignment(log_probs, model, joined_text, dion_segments)\n",
    "\n",
    "    # display(dion_segments[:5])\n",
    "    # print(joined_text[:500])\n",
    "    # display(timed_words[:5])\n",
    "    draw_time_deltas(aligned_timed_words)\n",
    "    \n",
    "    save_to_json({\n",
    "        'gigaam_timed_words': gigaam_timed_words,\n",
    "        'aligned_timed_words': aligned_timed_words,\n",
    "    }, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Иван Бондаренко', 13088),\n",
       " ('Roman', 11990),\n",
       " ('Elena Bruches', 11354),\n",
       " ('Виктория Кондрашук', 10895),\n",
       " ('Георгий', 9941),\n",
       " ('Vadim', 9411),\n",
       " ('Анастасия Рыбенко', 5058),\n",
       " ('Irina', 4296),\n",
       " ('Арсений', 4073),\n",
       " ('Анастасия', 3143),\n",
       " ('Георгий М', 3070),\n",
       " ('Даниил Гребенкин', 3036),\n",
       " ('Nikolay Bushkov', 2989),\n",
       " ('Дмитрий', 2866),\n",
       " ('v.alperovich | T-Bank', 2764),\n",
       " ('Ирина', 2576),\n",
       " ('Стас', 2248),\n",
       " ('ilyas', 1173),\n",
       " ('Михаил', 872),\n",
       " ('Den', 649),\n",
       " ('Ильдар (Онтико)', 498),\n",
       " ('Askar Timirgazin', 349),\n",
       " ('Игорь', 155),\n",
       " ('Иван Бондаренко ', 138),\n",
       " ('Денис Бондаренко ', 107),\n",
       " ('ivan_chernov', 104),\n",
       " ('Дари Батурова', 93),\n",
       " ('Konsatntin RSHB', 74),\n",
       " ('aleksandr medvedev', 64),\n",
       " ('Федьков Дмитрий', 18),\n",
       " (('Elena Bruches', 'Виктория Кондрашук'), 17),\n",
       " ('Дари', 17),\n",
       " ('Андрей Башкиров', 16),\n",
       " (('Георгий', 'Виктория Кондрашук'), 16),\n",
       " (('Иван Бондаренко', 'Виктория Кондрашук'), 11),\n",
       " (('Игорь', 'ilyas'), 6),\n",
       " (('Анастасия Рыбенко', 'Виктория Кондрашук'), 5),\n",
       " (('Den', 'Виктория Кондрашук'), 3),\n",
       " (('Elena Bruches', 'Георгий'), 3),\n",
       " (('Irina', 'Виктория Кондрашук'), 2),\n",
       " ('Константин', 2),\n",
       " (('Анастасия Рыбенко', 'Георгий'), 2),\n",
       " (('Георгий М', 'Иван Бондаренко'), 2),\n",
       " (('v.alperovich | T-Bank', 'Иван Бондаренко'), 2),\n",
       " (('Арсений', 'Дмитрий'), 2),\n",
       " ('Андрей', 1)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts: Counter[str | tuple[str, ...]] = Counter()\n",
    "\n",
    "for json_path in Path('/asr_datasets/dion/').glob('*.json'):\n",
    "    timed_words: list[AlignedDionTimedWord] = load_from_json(json_path)['aligned_timed_words']\n",
    "    counts = Counter([\n",
    "        (x.speaker if isinstance(x.speaker, str) else tuple(x.speaker))\n",
    "        for x in timed_words\n",
    "    ])\n",
    "    all_counts.update(counts)\n",
    "\n",
    "all_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
