{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import cast, Any\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pisets import load_sound # type: ignore\n",
    "import gigaam\n",
    "from gigaam.model import GigaAMASR\n",
    "from tqdm.auto import tqdm\n",
    "import scipy\n",
    "\n",
    "from asr_eval.models.gigaam import transcribe_with_gigaam_ctc, FREQ, encode\n",
    "from asr_eval.ctc.forced_alignment import forced_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cast(GigaAMASR, gigaam.load_model('ctc', device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = Path('tmp/dion/kondrashuk_2025-07-09T12_01_04+03_00.mp4')\n",
    "text_path = video_path.with_suffix('.txt')\n",
    "\n",
    "waveform = cast(npt.NDArray[np.floating[Any]], load_sound(video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_len_sec = 852.096, total_ticks = 21302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48d6ed905b2479b898b839014673882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(21303, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEGMENT_SIZE_SEC = 20\n",
    "SEGMENT_SHIFT_SEC = 6\n",
    "TICK_SIZE = 1 / FREQ\n",
    "\n",
    "total_len_sec = len(waveform) / 16_000\n",
    "total_ticks = int(total_len_sec / TICK_SIZE)\n",
    "print(f'{total_len_sec = }, {total_ticks = }')\n",
    "\n",
    "SAMPLING_RATE = gigaam.preprocess.SAMPLE_RATE\n",
    "\n",
    "class LogProbsWindow:\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_time: float,  # can be negative\n",
    "        end_time: float,\n",
    "        waveform_16k: npt.NDArray[np.floating[Any]],\n",
    "        model: GigaAMASR\n",
    "    ):\n",
    "        total_len_sec = len(waveform_16k) / SAMPLING_RATE\n",
    "        \n",
    "        clipped_start_time = np.clip(start_time, 0, total_len_sec)\n",
    "        clipped_end_time = np.clip(end_time, 0, total_len_sec)\n",
    "        \n",
    "        self.clipped_start_ticks = int(clipped_start_time * FREQ)\n",
    "        clipped_end_ticks = int(clipped_end_time * FREQ)\n",
    "        \n",
    "        clipped_start_pos = int(self.clipped_start_ticks * TICK_SIZE * SAMPLING_RATE)\n",
    "        clipped_end_pos = int(clipped_end_ticks * TICK_SIZE * SAMPLING_RATE)\n",
    "        \n",
    "        waveform_chunk = waveform[clipped_start_pos : clipped_end_pos]\n",
    "        self.log_probs = transcribe_with_gigaam_ctc(model, [waveform_chunk])[0].log_probs\n",
    "        \n",
    "        assert np.allclose(self.clipped_start_ticks + len(self.log_probs), clipped_end_ticks, atol=1.1)\n",
    "        self.clipped_end_ticks = self.clipped_start_ticks + len(self.log_probs)\n",
    "        \n",
    "        clip_ratio_start = (clipped_start_time - start_time) / (end_time - start_time)\n",
    "        clip_ratio_end = (clipped_end_time - start_time) / (end_time - start_time)\n",
    "        \n",
    "        self.weights = scipy.stats.beta.pdf(\n",
    "            np.linspace(clip_ratio_start, clip_ratio_end, num=len(self.log_probs)), a=5, b=5\n",
    "        )\n",
    "        self.weights /= self.weights.max()\n",
    "\n",
    "def average_logp_windows(windows: list[LogProbsWindow]) -> npt.NDArray[np.floating[Any]]:\n",
    "    max_ticks = max(window.clipped_end_ticks for window in windows)\n",
    "    \n",
    "    sum_weights = np.zeros(max_ticks)\n",
    "    for window in windows:\n",
    "        sum_weights[window.clipped_start_ticks:window.clipped_end_ticks] += window.weights\n",
    "\n",
    "    averaged_log_probs = np.zeros((max_ticks, windows[0].log_probs.shape[1]))\n",
    "    for window in windows:\n",
    "        span = slice(window.clipped_start_ticks, window.clipped_end_ticks)\n",
    "        averaged_log_probs[span] += (\n",
    "            window.log_probs * (window.weights / sum_weights[span])[:, None]\n",
    "        )\n",
    "    \n",
    "    return averaged_log_probs\n",
    "\n",
    "windows: list[LogProbsWindow] = []\n",
    "\n",
    "for center in tqdm(np.arange(0, total_len_sec, step=SEGMENT_SHIFT_SEC)):\n",
    "    start = center - SEGMENT_SIZE_SEC / 2  # can be negative\n",
    "    end = center + SEGMENT_SIZE_SEC / 2\n",
    "    windows.append(LogProbsWindow(start, end, waveform, model))\n",
    "\n",
    "averaged_log_probs = average_logp_windows(windows)\n",
    "averaged_log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DionSegment(approx_start_time=11.0, speaker='Анастасия', text='георгий', text_start_pos=0, text_end_pos=7),\n",
       " DionSegment(approx_start_time=11.0, speaker='Анастасия', text='тебя не слышного', text_start_pos=8, text_end_pos=24),\n",
       " DionSegment(approx_start_time=21.0, speaker='Анастасия', text='так', text_start_pos=25, text_end_pos=28),\n",
       " DionSegment(approx_start_time=25.0, speaker='Анастасия', text='вадим', text_start_pos=29, text_end_pos=34),\n",
       " DionSegment(approx_start_time=26.0, speaker='Анастасия', text='у тебя есть какие то вопросы', text_start_pos=35, text_end_pos=63),\n",
       " DionSegment(approx_start_time=28.0, speaker='Георгий', text='агайнело', text_start_pos=64, text_end_pos=72),\n",
       " DionSegment(approx_start_time=30.0, speaker='Георгий', text='всем привет', text_start_pos=73, text_end_pos=84)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "георгий тебя не слышного так вадим у тебя есть какие то вопросы агайнело всем привет да привет так что давайте начинать наверное или мы под ждем еще да я и спросила может быть есть какие то вопросы как с которых имеет смысл начать да но у меня основное наверное хотелось бы там поговорить про реот модельку вот если я там еще ничего не забыл вот угу ну и по остальным там статусам пробежаться по быстрому а так сегодня кажется можем быстро разойтись ну да давай сначала по обзорам собственно завтра по длинному контексту потом у нас на следующую неделю предварительно с шестнадцатого по восемнадцатое тоже от вас нужно будет время потому что там будет ну напомню полное название твою темы по мойте агентам системе а да вот то есть с шестнадцатого по восемнадцатое посмотрите и потом будем готовы в период тридцатого июля по первое августа провести последний большой третий темь да хорошо окей ну там я посмотрю тогда по слоту мы отправили также какой то раз угу угу да хорошо вот ну то есть собственн\n"
     ]
    }
   ],
   "source": [
    "def filter_encodable_tokens(text: str, model: GigaAMASR) -> str:\n",
    "    assert model.decoding.tokenizer.charwise\n",
    "    text = text.lower().replace('ё', 'е').replace('-', ' ')\n",
    "    return ''.join(char for char in text if char in model.decoding.tokenizer.vocab)\n",
    "\n",
    "@dataclass\n",
    "class DionSegment:\n",
    "    approx_start_time: float\n",
    "    speaker: str\n",
    "    text: str\n",
    "    text_start_pos: int\n",
    "    text_end_pos: int\n",
    "\n",
    "joined_text = ''\n",
    "segments: list[DionSegment] = []\n",
    "for record in text_path.read_text(encoding='utf-8-sig').split('\\n\\n'):\n",
    "    start_time_str, speaker, _, text = record.split('\\n')\n",
    "    \n",
    "    text = text[2:].strip()  # skip \"- \" prefix in the file\n",
    "    text = filter_encodable_tokens(text, model)\n",
    "    \n",
    "    try:\n",
    "        start_time = datetime.strptime(start_time_str, '%H:%M:%S') - datetime(1900, 1, 1)\n",
    "    except ValueError:\n",
    "        start_time = datetime.strptime(start_time_str, '%M:%S') - datetime(1900, 1, 1)\n",
    "    \n",
    "    if len(joined_text):\n",
    "        joined_text += ' '\n",
    "    joined_text += text\n",
    "    \n",
    "    segments.append(DionSegment(\n",
    "        approx_start_time=start_time.total_seconds(),\n",
    "        speaker=speaker,\n",
    "        text=text,\n",
    "        text_start_pos=len(joined_text) - len(text),\n",
    "        text_end_pos=len(joined_text),\n",
    "    ))\n",
    "    \n",
    "display(segments[:7])\n",
    "print(joined_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_per_frame, scores_per_frame, true_tokens_pos = forced_alignment(\n",
    "    log_probs=averaged_log_probs,\n",
    "    true_tokens=encode(model, joined_text),\n",
    "    blank_id=model.decoding.blank_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TimedWord(start_time=9.08, end_time=9.56, speaker='Анастасия', text='георгий', uncertainty_score=1.92),\n",
       " TimedWord(start_time=9.8, end_time=9.96, speaker='Анастасия', text='тебя', uncertainty_score=1.2),\n",
       " TimedWord(start_time=10.12, end_time=10.2, speaker='Анастасия', text='не', uncertainty_score=1.2),\n",
       " TimedWord(start_time=10.28, end_time=10.76, speaker='Анастасия', text='слышного', uncertainty_score=1.2),\n",
       " TimedWord(start_time=19.08, end_time=19.32, speaker='Анастасия', text='так', uncertainty_score=1.92),\n",
       " TimedWord(start_time=23.48, end_time=23.8, speaker='Анастасия', text='вадим', uncertainty_score=1.52),\n",
       " TimedWord(start_time=23.92, end_time=23.96, speaker='Анастасия', text='у', uncertainty_score=2.08)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class TimedWord:\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    speaker: str\n",
    "    text: str\n",
    "    uncertainty_score: float\n",
    "\n",
    "timed_words: list[TimedWord] = []\n",
    "for segment in segments:\n",
    "    \n",
    "    start_frame, _ = true_tokens_pos[segment.text_start_pos]\n",
    "    uncertainty_score = abs(start_frame / FREQ - segment.approx_start_time)\n",
    "    assert uncertainty_score < 5, (\n",
    "        'Forced alignment failed to match Dion timings'\n",
    "    )\n",
    "    \n",
    "    for match in re.finditer(r'\\w+', segment.text):\n",
    "        start_frame, _ = true_tokens_pos[segment.text_start_pos + match.start()]\n",
    "        _, end_frame = true_tokens_pos[segment.text_start_pos + match.end() - 1]\n",
    "        timed_words.append(TimedWord(\n",
    "            start_time=start_frame / FREQ,\n",
    "            end_time=end_frame / FREQ,\n",
    "            speaker=segment.speaker,\n",
    "            text=match.group(),\n",
    "            uncertainty_score=round(uncertainty_score, 3),\n",
    "        ))\n",
    "        \n",
    "timed_words[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
