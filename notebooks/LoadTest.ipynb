{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "import threading\n",
    "import time\n",
    "from textwrap import shorten\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from datasets import Dataset, load_dataset, Audio # type: ignore\n",
    "import gigaam\n",
    "from gigaam.model import GigaAMASR\n",
    "from tqdm.auto import tqdm\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from asr_eval.streaming.sender import BaseStreamingAudioSender, StreamingAudioSender\n",
    "from asr_eval.datasets.recording import Recording\n",
    "from asr_eval.align.timings import CannotFillTimings\n",
    "from asr_eval.streaming.evaluation import prepare_audio_format\n",
    "from asr_eval.streaming.models.vosk import VoskStreaming\n",
    "from asr_eval.utils.misc import new_uid\n",
    "from asr_eval.streaming.buffer import ID_TYPE\n",
    "from asr_eval.streaming.model import InputBuffer, OutputChunk, Signal, InputChunk, TranscriptionChunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cast(\n",
    "    Dataset, # type: ignore\n",
    "    load_dataset('bond005/sberdevices_golos_100h_farfield')['test'].take(100) # type: ignore\n",
    "    # load_dataset('bond005/podlodka_speech')['test'] #.take(100) # type: ignore\n",
    "    .cast_column('audio', Audio(sampling_rate=16_000)) # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gigaam_model = cast(GigaAMASR, gigaam.load_model('ctc', device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings: list[Recording] = []\n",
    "for sample in tqdm(dataset): # type: ignore\n",
    "    try:\n",
    "        recordings.append(Recording.from_sample(sample, use_gigaam=gigaam_model)) # type: ignore\n",
    "    except CannotFillTimings:\n",
    "        continue\n",
    "\n",
    "len(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = VoskStreaming(model_name='vosk-model-ru-0.42', chunk_length_sec=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_lengths = [\n",
    "    cast(float, len(sample['audio']['array']) / sample['audio']['sampling_rate']) # type: ignore\n",
    "    for sample in dataset # type: ignore\n",
    "]\n",
    "avg_audio_len = np.mean(audio_lengths)\n",
    "print(f'{avg_audio_len = :.2f} (min {min(audio_lengths):.2f}, max {max(audio_lengths):.2f})')\n",
    "\n",
    "TICK_SIZE = 0.1\n",
    "N_TICKS = 36000\n",
    "START_N_THREADS = 10\n",
    "FINISH_N_THREADS = 20\n",
    "\n",
    "N_SENDS_PER_TICK_PER_THREAD = TICK_SIZE / avg_audio_len\n",
    "\n",
    "expected_n_threads_for_each_tick = np.linspace(START_N_THREADS, FINISH_N_THREADS, num=N_TICKS)\n",
    "expected_n_sends_for_each_tick = expected_n_threads_for_each_tick * N_SENDS_PER_TICK_PER_THREAD\n",
    "\n",
    "seed = None\n",
    "rng = np.random.default_rng(seed)\n",
    "n_sends_for_each_tick = rng.poisson(expected_n_sends_for_each_tick)\n",
    "\n",
    "# plt.plot(expected_n_sends_for_each_tick)\n",
    "# plt.plot(np.convolve(n_sends_for_each_tick, np.ones(100) / 100))\n",
    "\n",
    "senders_and_delays: dict[ID_TYPE, tuple[BaseStreamingAudioSender, float]] = {}\n",
    "\n",
    "for tick_idx, n_sends in enumerate(n_sends_for_each_tick):\n",
    "    start_time = tick_idx * TICK_SIZE\n",
    "    \n",
    "    for _ in range(n_sends):\n",
    "        recording = cast(Recording, rng.choice(recordings)) # type: ignore\n",
    "        assert recording.waveform is not None\n",
    "        \n",
    "        audio, array_len_per_sec = prepare_audio_format(recording.waveform, asr)\n",
    "        sender = StreamingAudioSender(\n",
    "            audio=audio,\n",
    "            id=new_uid(),\n",
    "            array_len_per_sec=array_len_per_sec,\n",
    "            real_time_interval_sec=1 / 5,\n",
    "            speed_multiplier=1,\n",
    "        )\n",
    "        senders_and_delays[sender.id] = (sender, start_time)\n",
    "\n",
    "print(f'{len(senders_and_delays) = }')\n",
    "\n",
    "asr.start_thread()\n",
    "\n",
    "current_sending_ids: set[ID_TYPE] = set()\n",
    "current_transcribing_ids: set[ID_TYPE] = set()\n",
    "current_transcribing_ids_lock = threading.Lock()\n",
    "\n",
    "def sender_wrapper_fn(sender: BaseStreamingAudioSender, send_to: InputBuffer):\n",
    "    with current_transcribing_ids_lock:\n",
    "        # print('start sending', sender.id)\n",
    "        current_transcribing_ids.add(sender.id)\n",
    "        current_sending_ids.add(sender.id)\n",
    "        # print('current_sending_ids', current_sending_ids, flush=True)\n",
    "    sender.start_sending(send_to)\n",
    "    sender.join()\n",
    "    with current_transcribing_ids_lock:\n",
    "        current_sending_ids.remove(sender.id)\n",
    "\n",
    "sender_timers: list[threading.Timer] = [\n",
    "    threading.Timer(delay, sender_wrapper_fn, args=(sender, asr.input_buffer))\n",
    "    for sender, delay in senders_and_delays.values()\n",
    "]\n",
    "\n",
    "outputs_finished: dict[ID_TYPE, list[OutputChunk]] = {}\n",
    "outputs_not_finished: dict[ID_TYPE, list[OutputChunk]] = {\n",
    "    sender.id: [] for sender, _ in senders_and_delays.values()\n",
    "}\n",
    "outputs_sequence: list[tuple[InputChunk, OutputChunk]] = []\n",
    "outputs_lock = threading.Lock()\n",
    "\n",
    "def find_input_chunk(id: ID_TYPE, output_chunk: OutputChunk) -> InputChunk:\n",
    "    sender, _ = senders_and_delays[id]\n",
    "    with sender.history_lock:\n",
    "        for input_chunk in sender.history:\n",
    "            if input_chunk.end_time >= output_chunk.seconds_processed:\n",
    "                return input_chunk\n",
    "        raise AssertionError('not found')\n",
    "\n",
    "def receiver_thread_fn():\n",
    "    while True:\n",
    "        with outputs_lock:\n",
    "            if len(outputs_not_finished) == 0:\n",
    "                print('receiver thread finished')\n",
    "                return\n",
    "        try:\n",
    "            output_chunk, id = asr.output_buffer.get()\n",
    "            # print(f'received chunk for {id}')\n",
    "        except RuntimeError as e:\n",
    "            print(f'receiver thread interrupted: {e}')\n",
    "            return\n",
    "        \n",
    "        with outputs_lock:\n",
    "            assert id in current_transcribing_ids, f'cannot find id {id}'\n",
    "            assert id in outputs_not_finished, f'received output chunk for unknown id {id}'\n",
    "            outputs_not_finished[id].append(output_chunk)\n",
    "            \n",
    "            outputs_sequence.append((find_input_chunk(id, output_chunk), output_chunk))\n",
    "            \n",
    "            if output_chunk.data is Signal.FINISH:\n",
    "                with current_transcribing_ids_lock:\n",
    "                    current_transcribing_ids.remove(id)\n",
    "                outputs_finished[id] = outputs_not_finished[id]\n",
    "                del outputs_not_finished[id]\n",
    "                # text = TranscriptionChunk.join(outputs_finished[id])\n",
    "                # print(f'Transcribed {id}: {shorten(text, width=80)}', flush=True)\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class LoadStats:\n",
    "    n_transcribing: int\n",
    "    n_sending: int\n",
    "    delays_for_last_sec: list[float]\n",
    "    \n",
    "    def report(self) -> str:\n",
    "        delays = self.delays_for_last_sec\n",
    "        return (\n",
    "            f'transcribing now: {self.n_transcribing:4d}'\n",
    "            f'    sending now: {self.n_sending:4d}'\n",
    "            f'    out.chunks/sec: {len(delays):5d}'\n",
    "            f'    mean delay: {np.mean(delays) if len(delays) else np.nan:6.1f}'\n",
    "            f'    median delay: {np.median(delays) if len(delays) else np.nan:6.1f}'\n",
    "            f'    max delay: {np.max(delays) if len(delays) else np.nan:6.1f}'\n",
    "        )\n",
    "   \n",
    "stats_history: list[LoadStats] = []  # access only from watcher_thread_fn\n",
    "\n",
    "def stop_testing():\n",
    "    for timer in sender_timers:\n",
    "        timer.cancel()\n",
    "    asr.stop_thread()\n",
    "\n",
    "def watcher_thread_fn():  # todo use async - await?\n",
    "    processed_sequence_size = 0\n",
    "    for sec_idx in itertools.count():\n",
    "        time.sleep(1)\n",
    "        with current_transcribing_ids_lock:\n",
    "            if len(outputs_not_finished) == 0:\n",
    "                break\n",
    "            n_transcribing = len(current_transcribing_ids)\n",
    "            n_sending = len(current_sending_ids)\n",
    "        with outputs_lock:\n",
    "            new_data = outputs_sequence[processed_sequence_size:]\n",
    "            processed_sequence_size = len(outputs_sequence)\n",
    "            delays = [\n",
    "                output_chunk.put_timestamp - input_chunk.put_timestamp\n",
    "                for input_chunk, output_chunk in new_data\n",
    "            ]\n",
    "        stats = LoadStats(\n",
    "            n_transcribing=n_transcribing,\n",
    "            n_sending=n_sending,\n",
    "            delays_for_last_sec=delays\n",
    "        )\n",
    "        stats_history.append(stats)\n",
    "        print(stats.report())\n",
    "        \n",
    "        if np.mean(stats.delays_for_last_sec) > 40:\n",
    "            print('stopping testing')\n",
    "            stop_testing()\n",
    "            # display_stats_history(stats_history)\n",
    "            return\n",
    "        \n",
    "        # if sec_idx % 10 == 9:\n",
    "        #     IPython.display.clear_output()\n",
    "        #     display_stats_history(stats_history)\n",
    "            \n",
    "    print('watcher done')\n",
    "    \n",
    "\n",
    "for timer in sender_timers:\n",
    "    timer.start()\n",
    "    \n",
    "receiver_thread = threading.Thread(target=receiver_thread_fn)\n",
    "receiver_thread.start()    \n",
    "\n",
    "watcher_thread = threading.Thread(target=watcher_thread_fn)\n",
    "watcher_thread.start()\n",
    "\n",
    "try:\n",
    "    receiver_thread.join()\n",
    "    watcher_thread.join()\n",
    "except KeyboardInterrupt:\n",
    "    with outputs_lock:\n",
    "        outputs_not_finished = {}  # to stop watcher\n",
    "    receiver_thread.join()\n",
    "    watcher_thread.join()\n",
    "asr.stop_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats_history(stats_history: list[LoadStats]):\n",
    "    plt.figure(figsize=(15, 8)) # type: ignore\n",
    "    ax1, ax2 = plt.gca(), plt.gca().twinx()\n",
    "    \n",
    "    median_lags = [\n",
    "        np.median(stats.delays_for_last_sec) if len(stats.delays_for_last_sec) else np.nan\n",
    "        for stats in stats_history\n",
    "    ]\n",
    "    \n",
    "    max_lags = [\n",
    "        np.max(stats.delays_for_last_sec) if len(stats.delays_for_last_sec) else np.nan\n",
    "        for stats in stats_history\n",
    "    ]\n",
    "    \n",
    "    ax2.plot(median_lags, label='median lag', alpha=0.5, color='g', zorder=2) # type: ignore\n",
    "    ax2.plot(max_lags, label='max lag', alpha=0.5, color='r', zorder=1) # type: ignore\n",
    "    ax2.legend() # type: ignore\n",
    "    \n",
    "    n_sending = [stats.n_sending for stats in stats_history]\n",
    "    n_trailing = [stats.n_transcribing - stats.n_sending for stats in stats_history]\n",
    "    \n",
    "    ax1.bar( # type: ignore\n",
    "        x=range(len(stats_history)),\n",
    "        height=n_sending,\n",
    "        width=1,\n",
    "        color='blue',\n",
    "        label='N sending',\n",
    "        zorder=-10,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    ax1.bar( # type: ignore\n",
    "        x=range(len(stats_history)),\n",
    "        height=n_trailing,\n",
    "        bottom=n_sending,\n",
    "        width=1,\n",
    "        color='red',\n",
    "        label='N trailing',\n",
    "        zorder=-10,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    smooth = 20\n",
    "    if len(n_sending) > 20:\n",
    "        smoothed = np.convolve(n_sending, np.ones(smooth) / smooth, mode='valid')\n",
    "        dx = (len(n_sending) - len(smoothed)) // 2\n",
    "        ax1.plot( # type: ignore\n",
    "            np.arange(len(smoothed)) + dx,\n",
    "            smoothed,\n",
    "            color='b',\n",
    "            label='N sending (smoothed plot)'\n",
    "        )\n",
    "    \n",
    "    ax1.legend(loc='upper left') # type: ignore\n",
    "    ax2.legend(loc='upper center') # type: ignore\n",
    "    \n",
    "    ax1.set_ylim(0, max(n_sending) * 1.5)\n",
    "    ax2.set_ylim(0, np.quantile(max_lags, 0.95)) # type: ignore\n",
    "    \n",
    "    plt.xlabel('Test duration, sec') # type: ignore\n",
    "    ax1.set_ylabel('N transcribing') # type: ignore\n",
    "    ax2.set_ylabel('Lag, sec') # type: ignore\n",
    "    \n",
    "    plt.show() # type: ignore\n",
    "\n",
    "display_stats_history(stats_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "\n",
    "on_put_in_output_buffer\n",
    "- find the corresponding input chunk in `input_history`\n",
    "- save their delay into a `delay_history`\n",
    "on_put_in_input_buffer\n",
    "- save to `input_history` (not using sender.history since we may receive not from sender)\n",
    "start_testing\n",
    "- shedule all senders\n",
    "\n",
    "asr.start_thread()\n",
    "asr.input_buffer.on_put(on_put_in_input_buffer)\n",
    "asr.output_buffer.on_put(on_put_in_output_buffer)\n",
    "start_sending()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
