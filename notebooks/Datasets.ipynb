{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading multivariant_v1_200\n",
      "{'testset_name': 'multivariant_v1_200', 'n_samples': 200, 'n_hours': 7.306692579994961}\n",
      "Loading youtube_lectures\n",
      "{'testset_name': 'youtube_lectures', 'n_samples': 7, 'n_hours': 2.8012888194444443}\n",
      "Loading golos_farfield\n",
      "{'testset_name': 'golos_farfield', 'n_samples': 1916, 'n_hours': 1.407983611111111}\n",
      "Loading rulibrispeech\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af517086a744160922f3545f0c55f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testset_name': 'rulibrispeech', 'n_samples': 1352, 'n_hours': 2.6462166666666667}\n",
      "Loading podlodka\n",
      "{'testset_name': 'podlodka', 'n_samples': 20, 'n_hours': 0.1351415798611111}\n",
      "Loading podlodka_full\n",
      "{'testset_name': 'podlodka_full', 'n_samples': 107, 'n_hours': 0.6855049066987907}\n",
      "Loading sova_rudevices\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6170770e3a1347898b6062c0b1539900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testset_name': 'sova_rudevices', 'n_samples': 5799, 'n_hours': 5.809085399305556}\n",
      "Loading resd\n",
      "{'testset_name': 'resd', 'n_samples': 280, 'n_hours': 0.46099137703924165}\n",
      "Loading fleurs\n",
      "{'testset_name': 'fleurs', 'n_samples': 775, 'n_hours': 2.498283333333333}\n",
      "Loading speech_massive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25b9a6a026a4c0181d9d12bece8b22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testset_name': 'speech_massive', 'n_samples': 2974, 'n_hours': 3.4382683333333333}\n",
      "Loading common_voice_17_0\n",
      "{'testset_name': 'common_voice_17_0', 'n_samples': 10203, 'n_hours': 15.871770254629629}\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from asr_eval.datasets.datasets import *\n",
    "\n",
    "\n",
    "load_fns = (\n",
    "    load_multivariant_v1_200,\n",
    "    load_youtube_lectures,\n",
    "    load_golos_farfield,\n",
    "    load_rulibrispeech,\n",
    "    load_podlodka,\n",
    "    load_podlodka_full,\n",
    "    load_sova_rudevices,\n",
    "    load_resd,\n",
    "    load_fleurs,\n",
    "    load_speech_massive,\n",
    "    load_common_voice_17_0\n",
    ")\n",
    "\n",
    "def get_audio_len(sample: dict[str, Any]):\n",
    "    return len(sample['audio']['array']) / sample['audio']['sampling_rate']\n",
    "\n",
    "infos = []\n",
    "\n",
    "for load_fn in load_fns:\n",
    "    dataset_name = load_fn.__name__.removeprefix('load_')\n",
    "    \n",
    "    print(f'Loading {dataset_name}')\n",
    "    \n",
    "    try:\n",
    "        dataset = load_fn()\n",
    "        \n",
    "        total_size_sec = sum([get_audio_len(sample) for sample in dataset]) # type: ignore\n",
    "        \n",
    "        infos.append(info := { # type: ignore\n",
    "            'testset_name': dataset_name,\n",
    "            'n_samples': len(dataset),\n",
    "            'n_hours': total_size_sec / 3600,\n",
    "        })\n",
    "        print(info)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           testset_name  n_samples    n_hours\n",
      "0   multivariant_v1_200        200   7.306693\n",
      "1      youtube_lectures          7   2.801289\n",
      "2        golos_farfield       1916   1.407984\n",
      "3         rulibrispeech       1352   2.646217\n",
      "4              podlodka         20   0.135142\n",
      "5         podlodka_full        107   0.685505\n",
      "6        sova_rudevices       5799   5.809085\n",
      "7                  resd        280   0.460991\n",
      "8                fleurs        775   2.498283\n",
      "9        speech_massive       2974   3.438268\n",
      "10    common_voice_17_0      10203  15.871770\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.DataFrame(infos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from asr_eval.datasets.datasets import *\n",
    "dataset = load_youtube_lectures()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "samples = list(dataset)\n",
    "for sample in samples:\n",
    "    sample['audio']['array'] = np.array(sample['audio']['array'])\n",
    "\n",
    "from datasets import Features, Value\n",
    "\n",
    "dataset = Dataset.from_list(samples, features=Features({\n",
    "    'audio': Audio(decode=True),\n",
    "    'name': Value('string'),\n",
    "    'transcription': Value('string'),\n",
    "    'noise': Value('string'),\n",
    "    'domain': Value('string'),\n",
    "}))\n",
    "\n",
    "dataset.save_to_disk('/asr_datasets/long_audio_youtube_lectures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oleg/asr-eval\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ba0b0be5ec42e3ae8936b843b98ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, Features, Value, Sequence, Audio, load_from_disk\n",
    "import librosa\n",
    "\n",
    "samples = [\n",
    "    {\n",
    "        'audio': 'audio.wav',\n",
    "        'transcription': 'чипи чипи чапа чапа',\n",
    "        'utterances': {\n",
    "            'start': [0, 10],\n",
    "            'end': [5, 15],\n",
    "            'text': ['чипи чипи', 'чапа чапа'],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'audio': 'audio copy.wav',\n",
    "        'transcription': 'прибыть в 314 кабинет',\n",
    "        'utterances': {\n",
    "            'start': [2],\n",
    "            'end': [5],\n",
    "            'text': ['прибыть в 314 кабинет'],\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "\n",
    "for sample in samples:\n",
    "    audio_path = sample['audio']\n",
    "    waveform, _ = librosa.load(audio_path, sr=SAMPLING_RATE) # type: ignore\n",
    "    sample['audio'] = {\n",
    "        'array': waveform,\n",
    "        'sampling_rate': SAMPLING_RATE,\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_list(samples, features=Features({ # type: ignore\n",
    "    'audio': Audio(decode=True),\n",
    "    'transcription': Value('string'),\n",
    "    'utterances': Sequence({\n",
    "        'start': Value('float'),\n",
    "        'end': Value('float'),\n",
    "        'text': Value('string'),\n",
    "    })\n",
    "}))\n",
    "\n",
    "dataset.save_to_disk('dataset1')\n",
    "\n",
    "dataset = load_from_disk('dataset1')\n",
    "assert len(dataset) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
