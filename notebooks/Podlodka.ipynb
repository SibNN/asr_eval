{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oleg\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "import typing\n",
    "from typing import Any, cast\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import gigaam\n",
    "from gigaam.model import GigaAMASR\n",
    "import jiwer\n",
    "from datasets import Dataset, load_dataset, Audio\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from asr_eval.data import Recording\n",
    "from asr_eval.align.data import Token\n",
    "from asr_eval.models.gigaam import EncodeError\n",
    "from asr_eval.streaming.sender import StreamingAudioSender, BaseStreamingAudioSender\n",
    "from asr_eval.streaming.caller import receive_full_transcription\n",
    "from asr_eval.streaming.models.vosk import VoskStreaming\n",
    "from asr_eval.streaming.model import TranscriptionChunk, InputChunk, OutputChunk\n",
    "from asr_eval.streaming.evaluation import RecordingStreamingEvaluation, PartialAlignment, get_partial_alignments, remap_time\n",
    "from asr_eval.streaming.plots import partial_alignment_diagram, visualize_history\n",
    "from asr_eval.streaming.timings import get_word_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/asr-eval/venv/lib/python3.12/site-packages/gigaam/__init__.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "gigaam_model = typing.cast(GigaAMASR, gigaam.load_model('ctc', device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ba89a307c943d1b0760e6375f6deab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# type: ignore\n",
    "\n",
    "name, split = 'bond005/podlodka_speech', 'test'\n",
    "dataset: Dataset = (\n",
    "    load_dataset(name)[split]\n",
    "    .cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    ")\n",
    "\n",
    "samples: list[Recording] = []\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    try:\n",
    "        samples.append(Recording.from_sample(\n",
    "            sample=dataset[i],\n",
    "            name=name,\n",
    "            split=split,\n",
    "            index=i,\n",
    "            use_gigaam=gigaam_model,\n",
    "        ))\n",
    "    except EncodeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    sample.evals = RecordingStreamingEvaluation()\n",
    "    sample.evals.id = sample.hf_uid\n",
    "    sample.evals.sender = StreamingAudioSender(\n",
    "        id=sample.evals.id,\n",
    "        audio=np.int16(sample.waveform * 32768).tobytes(),\n",
    "        array_len_per_sec=16_000 * 2,  # x2 because of the conversion float -> bytes\n",
    "        real_time_interval_sec=1 / 5,\n",
    "        speed_multiplier=1,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
      "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /home/oleg/.cache/vosk/vosk-model-ru-0.42/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from /home/oleg/.cache/vosk/vosk-model-ru-0.42/graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:297) Loading words from /home/oleg/.cache/vosk/vosk-model-ru-0.42/graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /home/oleg/.cache/vosk/vosk-model-ru-0.42/graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:315) Loading subtract G.fst model from /home/oleg/.cache/vosk/vosk-model-ru-0.42/rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:317) Loading CARPA model from /home/oleg/.cache/vosk/vosk-model-ru-0.42/rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:323) Loading RNNLM model from /home/oleg/.cache/vosk/vosk-model-ru-0.42/rnnlm/final.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing bond005/podlodka_speech/test/0\n",
      "Transcribed bond005/podlodka_speech/test/0: и поэтому использовать их в повседневности не получается мы вынуждены отступать\n",
      "Transcribing bond005/podlodka_speech/test/3\n",
      "Transcribed bond005/podlodka_speech/test/3: да это отсутствие долго живущие бранчей другими словами отсутствие какому- [...]\n",
      "Transcribing bond005/podlodka_speech/test/4\n",
      "Transcribed bond005/podlodka_speech/test/4: то есть мы в каждый момент времени знаем про звук ещё и какое-то такое [...]\n",
      "Transcribing bond005/podlodka_speech/test/5\n",
      "Transcribed bond005/podlodka_speech/test/5: и мне кажется абсолютно все замечали что детские крики раздражают там и ты [...]\n",
      "Transcribing bond005/podlodka_speech/test/6\n",
      "Transcribed bond005/podlodka_speech/test/6: неужто не может быть какое-то количество дискретных столбиков где каждый [...]\n",
      "Transcribing bond005/podlodka_speech/test/7\n",
      "Transcribed bond005/podlodka_speech/test/7: второй челлендж он чисто поисковая это собственно как делать этот поиск [...]\n",
      "Transcribing bond005/podlodka_speech/test/8\n",
      "Transcribed bond005/podlodka_speech/test/8: вот пришёл запрос мы для него нашли пул кандидатов треков кандидатов и на [...]\n",
      "Transcribing bond005/podlodka_speech/test/9\n",
      "Transcribed bond005/podlodka_speech/test/9: то в силу того что люди неспособны достать но особенно не профессионалы [...]\n",
      "Transcribing bond005/podlodka_speech/test/11\n",
      "Transcribed bond005/podlodka_speech/test/11: практически за насколько это был шит на прозвучит скорее бизнесово [...]\n",
      "Transcribing bond005/podlodka_speech/test/12\n",
      "Transcribed bond005/podlodka_speech/test/12: то как бы ну зачем мне смотреть и влоги прошлой версии системы там все [...]\n",
      "Transcribing bond005/podlodka_speech/test/13\n",
      "Transcribed bond005/podlodka_speech/test/13: про то как сейчас принято делать как раз такими распределённых каких-то [...]\n",
      "Transcribing bond005/podlodka_speech/test/14\n",
      "Transcribed bond005/podlodka_speech/test/14: построить запросы как раз вот между многими хвостами одновременно и по [...]\n",
      "Transcribing bond005/podlodka_speech/test/15\n",
      "Transcribed bond005/podlodka_speech/test/15: и вот такая архитектура долгое время доминировала её пытались [...]\n",
      "Transcribing bond005/podlodka_speech/test/16\n",
      "Transcribed bond005/podlodka_speech/test/16: краеугольным камнем любые алгоритмы машинного обучения является прежде [...]\n"
     ]
    }
   ],
   "source": [
    "# type: ignore\n",
    "\n",
    "asr = VoskStreaming(model_name='vosk-model-ru-0.42', chunk_length_sec=1)\n",
    "asr.start_thread()\n",
    "\n",
    "for sample in samples:\n",
    "    sample.evals.output_chunks = receive_full_transcription(\n",
    "        asr=asr,\n",
    "        sender=sample.evals.sender,\n",
    "        id=sample.evals.id,\n",
    "        send_all_without_delays=True,\n",
    "    )\n",
    "\n",
    "asr.stop_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    assert sample.evals is not None\n",
    "    assert sample.evals.sender is not None\n",
    "    assert sample.evals.output_chunks is not None\n",
    "    sample.evals.input_chunks_remapped, sample.evals.output_chunks_remapped = remap_time(\n",
    "        sample.evals.sender.get_send_times(), sample.evals.sender.history, sample.evals.output_chunks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d5123fdc4b4bcf9ede0247f80f80fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in tqdm(samples):\n",
    "    assert sample.evals is not None\n",
    "    assert sample.evals.input_chunks_remapped is not None\n",
    "    assert sample.evals.output_chunks_remapped is not None\n",
    "    sample.evals.partial_alignments = get_partial_alignments(\n",
    "        sample.evals.input_chunks_remapped,\n",
    "        sample.evals.output_chunks_remapped,\n",
    "        cast(list[Token], sample.transcription_words),\n",
    "        processes=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    assert sample.evals is not None\n",
    "    assert sample.evals.sender is not None\n",
    "    assert sample.evals.partial_alignments is not None\n",
    "    partial_alignment_diagram(\n",
    "        sample.evals.partial_alignments,\n",
    "        cast(list[Token], sample.transcription_words),\n",
    "        audio_len=cast(float, sample.evals.sender.history[-1].end_time),  # TODO: may be not precise\n",
    "        figsize=(12, 2),\n",
    "        y_type='processed',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': array([0.        , 0.24074074, 0.66666667, 0.74725275, 0.81065089,\n",
       "        0.79775281]),\n",
       " 'error': array([0.        , 0.18518519, 0.31372549, 0.25274725, 0.18934911,\n",
       "        0.20224719]),\n",
       " 'not_yet': array([1.        , 0.57407407, 0.01960784, 0.        , 0.        ,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from asr_eval.align.data import Match, Token\n",
    "\n",
    "stats: list[tuple[float, Literal['correct', 'error', 'not_yet']]] = []\n",
    "\n",
    "def get_center_time(token: Token):\n",
    "    return (token.start_time + token.end_time) / 2\n",
    "\n",
    "# TODO find a better way\n",
    "partial_alignments[-1].audio_seconds_processed = partial_alignments[-2].audio_seconds_processed\n",
    "\n",
    "for partial_alignment in partial_alignments:\n",
    "    # split into head and tail\n",
    "    head: list[Match] = []\n",
    "    tail: list[Match] = []\n",
    "    in_tail = True\n",
    "    for match in partial_alignment.alignment.matches[::-1]:\n",
    "        in_tail &= match.status == 'deletion'\n",
    "        if in_tail:\n",
    "            tail.insert(0, match)\n",
    "        else:\n",
    "            head.insert(0, match)\n",
    "            \n",
    "    sec_processed = cast(float, partial_alignment.audio_seconds_processed)\n",
    "    \n",
    "    # process head\n",
    "    for i, match in enumerate(head):\n",
    "        if match.status == 'correct':\n",
    "            for token in match.true:\n",
    "                stats.append((sec_processed - get_center_time(token), 'correct'))\n",
    "        elif match.status == 'insertion':\n",
    "            left_pos = max(\n",
    "                [0] + [token.end_time for match2 in head[:i] for token in match2.true]\n",
    "            )\n",
    "            right_pos = min(\n",
    "                [sec_processed] + [token.end_time for match2 in head[i + 1:] for token in match2.true]\n",
    "            )\n",
    "            stats.append((sec_processed - (left_pos + right_pos) / 2, 'error'))\n",
    "        else:\n",
    "            for token in match.true:\n",
    "                stats.append((sec_processed - get_center_time(token), 'error'))\n",
    "    \n",
    "    # process tail\n",
    "    for match in tail:\n",
    "        for token in match.true:\n",
    "            stats.append((sec_processed - get_center_time(token), 'not_yet'))\n",
    "\n",
    "\n",
    "counts: dict[Literal['correct', 'error', 'not_yet'], npt.NDArray[np.int64]] = {}\n",
    "\n",
    "bins = [0, 1, 2, 3, 5, 10, 1000]\n",
    "for status in 'correct', 'error', 'not_yet':\n",
    "    counts[status] = np.histogram([t for t, s in stats if s == status], bins=bins)[0]\n",
    "\n",
    "total_counts = sum(counts.values())\n",
    "\n",
    "ratios = {status: c / total_counts for status, c in counts.items()}\n",
    "ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import pairwise\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xrange = range(len(bins) - 1)\n",
    "plt.bar(xrange, height=ratios['correct']) # type: ignore\n",
    "plt.bar(xrange, height=ratios['error'], bottom=ratios['correct']) # type: ignore\n",
    "plt.bar(xrange, height=ratios['not_yet'], bottom=ratios['correct'] + ratios['error']) # type: ignore\n",
    "plt.gca().set_xticks(xrange) # type: ignore\n",
    "plt.gca().set_xticklabels([f'{a}-{b}' for a, b in pairwise(bins)]) # type: ignore\n",
    "plt.show() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Final transcription:', TranscriptionChunk.join(output_chunks))\n",
    "\n",
    "# true_token_id_to_time_span = {\n",
    "#     token.id: (start, end) for token, start, end in word_timings\n",
    "# }\n",
    "\n",
    "# last_word_end = [\n",
    "#     max([\n",
    "#         true_token_id_to_time_span[m.true[-1].id][-1]\n",
    "#         for m in partial_al.alignment.matches\n",
    "#         if m.status not in ('deletion', 'insertion')\n",
    "#     ] or [0])\n",
    "#     for partial_al in partial_alignments\n",
    "# ]\n",
    "\n",
    "# latency_sent = [p.audio_seconds_sent - end for p, end in zip(partial_alignments, last_word_end)]\n",
    "# print(f'Average latency (sent): {np.mean(latency_sent):.1f} sec')\n",
    "\n",
    "# latency_processed = [p.audio_seconds_processed - end for p, end in zip(partial_alignments, last_word_end)] # type: ignore\n",
    "# print(f'Average latency (processed): {np.mean(latency_processed):.1f} sec') # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
