{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import typing\n",
    "from typing import cast\n",
    "\n",
    "import gigaam\n",
    "from gigaam.model import GigaAMASR\n",
    "from datasets import Dataset, load_dataset, Audio\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from asr_eval.align.timings import CannotFillTimings\n",
    "from asr_eval.datasets.recording import Recording\n",
    "from asr_eval.models.gigaam import GigaAMEncodeError, encode\n",
    "from asr_eval.streaming.models.vosk import VoskStreaming\n",
    "from asr_eval.streaming.evaluation import default_evaluation_pipeline, RecordingStreamingEvaluation\n",
    "from asr_eval.streaming.plots import (\n",
    "    partial_alignments_plot,\n",
    "    visualize_history,\n",
    "    streaming_error_vs_latency_histogram,\n",
    "    latency_plot,\n",
    "    show_last_alignments,\n",
    ")\n",
    "from asr_eval.utils.serializing import save_to_json, load_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gigaam_model = typing.cast(GigaAMASR, gigaam.load_model('ctc', device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "samples: list[Recording] = []\n",
    "\n",
    "# name, split = 'mozilla-foundation/common_voice_17_0', 'test'  #, 'ru'\n",
    "name = 'bond005/podlodka_speech'\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    dataset: Dataset = (\n",
    "        load_dataset(name)[split]\n",
    "        .cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "        # .rename_column('sentence', 'transcription')\n",
    "    )\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        try:\n",
    "            samples.append(Recording.from_sample(\n",
    "                sample=dataset[i],\n",
    "                name=name,\n",
    "                split=split,\n",
    "                index=i,\n",
    "                use_gigaam=gigaam_model,\n",
    "            ))\n",
    "        except CannotFillTimings:\n",
    "            pass\n",
    "        if len(samples) >= 100:\n",
    "            break\n",
    "\n",
    "    print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = VoskStreaming(model_name='vosk-model-ru-0.42', chunk_length_sec=1)\n",
    "asr.start_thread()\n",
    "\n",
    "evals: list[RecordingStreamingEvaluation] = []\n",
    "for recording in tqdm(samples):\n",
    "    evals.append(default_evaluation_pipeline(recording, asr))\n",
    "    recording.waveform = None\n",
    "\n",
    "asr.stop_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json(evals, 'tmp/evals.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals: list[RecordingStreamingEvaluation] = load_from_json('tmp/evals.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = evals[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8)) # type: ignore\n",
    "partial_alignments_plot(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_history(eval.input_chunks, eval.output_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_error_vs_latency_histogram(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_plot(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8)) # type: ignore\n",
    "show_last_alignments(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
