{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "import typing\n",
    "from typing import cast\n",
    "\n",
    "import gigaam\n",
    "from gigaam.model import GigaAMASR\n",
    "from datasets import Dataset, load_dataset, Audio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from asr_eval.data import Recording\n",
    "from asr_eval.align.data import Token\n",
    "from asr_eval.models.gigaam import EncodeError\n",
    "from asr_eval.streaming.models.vosk import VoskStreaming\n",
    "from asr_eval.streaming.evaluation import default_evaluation_pipeline\n",
    "from asr_eval.streaming.plots import partial_alignment_diagram, streaming_error_vs_latency_diagram\n",
    "from asr_eval.serializing import save_to_json, load_from_json\n",
    "from asr_eval.utils import N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gigaam_model = typing.cast(GigaAMASR, gigaam.load_model('ctc', device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e20cac42fc4400fa7f87ae1d9550e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# type: ignore\n",
    "\n",
    "name, split = 'bond005/podlodka_speech', 'test'\n",
    "dataset: Dataset = (\n",
    "    load_dataset(name)[split]\n",
    "    .cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    ")\n",
    "\n",
    "samples: list[Recording] = []\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    try:\n",
    "        samples.append(Recording.from_sample(\n",
    "            sample=dataset[i],\n",
    "            name=name,\n",
    "            split=split,\n",
    "            index=i,\n",
    "            use_gigaam=gigaam_model,\n",
    "        ))\n",
    "    except EncodeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
      "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /home/oleg/.cache/vosk/vosk-model-ru-0.42/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from /home/oleg/.cache/vosk/vosk-model-ru-0.42/graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:297) Loading words from /home/oleg/.cache/vosk/vosk-model-ru-0.42/graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /home/oleg/.cache/vosk/vosk-model-ru-0.42/graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:315) Loading subtract G.fst model from /home/oleg/.cache/vosk/vosk-model-ru-0.42/rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:317) Loading CARPA model from /home/oleg/.cache/vosk/vosk-model-ru-0.42/rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:323) Loading RNNLM model from /home/oleg/.cache/vosk/vosk-model-ru-0.42/rnnlm/final.raw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f3962a266b4433aabbaccfc0e36c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing bond005/podlodka_speech/test/0\n",
      "Transcribed bond005/podlodka_speech/test/0: и поэтому использовать их в повседневности не получается мы вынуждены отступать\n",
      "Transcribing bond005/podlodka_speech/test/3\n",
      "Transcribed bond005/podlodka_speech/test/3: да это отсутствие долго живущие бранчей другими словами отсутствие какому- [...]\n",
      "Transcribing bond005/podlodka_speech/test/4\n",
      "Transcribed bond005/podlodka_speech/test/4: то есть мы в каждый момент времени знаем про звук ещё и какое-то такое [...]\n",
      "Transcribing bond005/podlodka_speech/test/5\n",
      "Transcribed bond005/podlodka_speech/test/5: и мне кажется абсолютно все замечали что детские крики раздражают там и ты [...]\n",
      "Transcribing bond005/podlodka_speech/test/6\n",
      "Transcribed bond005/podlodka_speech/test/6: неужто не может быть какое-то количество дискретных столбиков где каждый [...]\n",
      "Transcribing bond005/podlodka_speech/test/7\n",
      "Transcribed bond005/podlodka_speech/test/7: второй челлендж он чисто поисковая это собственно как делать этот поиск [...]\n",
      "Transcribing bond005/podlodka_speech/test/8\n",
      "Transcribed bond005/podlodka_speech/test/8: вот пришёл запрос мы для него нашли пул кандидатов треков кандидатов и на [...]\n",
      "Transcribing bond005/podlodka_speech/test/9\n",
      "Transcribed bond005/podlodka_speech/test/9: то в силу того что люди неспособны достать но особенно не профессионалы [...]\n",
      "Transcribing bond005/podlodka_speech/test/11\n",
      "Transcribed bond005/podlodka_speech/test/11: практически за насколько это был шит на прозвучит скорее бизнесово [...]\n",
      "Transcribing bond005/podlodka_speech/test/12\n",
      "Transcribed bond005/podlodka_speech/test/12: то как бы ну зачем мне смотреть и влоги прошлой версии системы там все [...]\n",
      "Transcribing bond005/podlodka_speech/test/13\n",
      "Transcribed bond005/podlodka_speech/test/13: про то как сейчас принято делать как раз такими распределённых каких-то [...]\n",
      "Transcribing bond005/podlodka_speech/test/14\n",
      "Transcribed bond005/podlodka_speech/test/14: построить запросы как раз вот между многими хвостами одновременно и по [...]\n",
      "Transcribing bond005/podlodka_speech/test/15\n",
      "Transcribed bond005/podlodka_speech/test/15: и вот такая архитектура долгое время доминировала её пытались [...]\n",
      "Transcribing bond005/podlodka_speech/test/16\n",
      "Transcribed bond005/podlodka_speech/test/16: краеугольным камнем любые алгоритмы машинного обучения является прежде [...]\n"
     ]
    }
   ],
   "source": [
    "asr = VoskStreaming(model_name='vosk-model-ru-0.42', chunk_length_sec=1)\n",
    "asr.start_thread()\n",
    "for recording in tqdm(samples):\n",
    "    recording.evals = default_evaluation_pipeline(recording, asr)\n",
    "    recording.waveform = None\n",
    "asr.stop_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json(samples, 'tmp/samples.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples: list[Recording] = load_from_json('tmp/samples.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = samples[6]\n",
    "\n",
    "partial_alignment_diagram(\n",
    "    N(N(recording.evals).partial_alignments),\n",
    "    cast(list[Token], recording.transcription_words),\n",
    "    start_real_time=N(N(N(recording.evals).input_chunks)[0].put_timestamp),\n",
    "    end_real_time=N(N(N(recording.evals).output_chunks)[-1].put_timestamp),\n",
    "    figsize=(12, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_error_vs_latency_diagram(sum([\n",
    "    partial_alignment.get_error_positions()\n",
    "    for recording in samples\n",
    "    for partial_alignment in recording.evals.partial_alignments # type: ignore\n",
    "], [])) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
