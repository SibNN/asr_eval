{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CacheInfo(hits=79600, misses=40401, maxsize=None, currsize=40401)\n",
      "errs 67\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "# from functools import lru_cache\n",
    "from typing import Any\n",
    "import uuid\n",
    "\n",
    "from cachetools import cached\n",
    "from cachetools.keys import hashkey\n",
    "import numpy as np\n",
    "\n",
    "class Anything:\n",
    "    def __eq__(self, other: Any) -> bool: return True\n",
    "    def __repr__(self) -> str: return '<?>'\n",
    "    __str__ = __repr__\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    value: str | Anything\n",
    "    uid: str = field(default_factory=lambda: uuid.uuid4().hex)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.value)\n",
    "\n",
    "@dataclass\n",
    "class MultiVariant:\n",
    "    options: list[list[Token]]\n",
    "    uid: str = field(default_factory=lambda: uuid.uuid4().hex)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.options)\n",
    "\n",
    "def tokens_from_text(text: str) -> list[Token]:\n",
    "    return [Token(t) for t in text.split()]\n",
    "    \n",
    "def multi_variant_from_texts(texts: list[str]) -> MultiVariant:\n",
    "    return MultiVariant([tokens_from_text(text) for text in texts])\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Match:\n",
    "    true: list[Token]\n",
    "    pred: list[Token]\n",
    "    true_len: int\n",
    "    n_errs: int\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pair(cls, true: list[Token], pred: list[Token]) -> Match:\n",
    "        assert len(true) > 0 or len(pred) > 0\n",
    "        return Match(\n",
    "            true=true,\n",
    "            pred=pred,\n",
    "            true_len=len(true),\n",
    "            n_errs=(\n",
    "                0\n",
    "                if [t.value for t in true] == [t.value for t in pred]\n",
    "                or (len(true) == 1 and isinstance(true[0].value, Anything))\n",
    "                else max(len(true), len(pred))\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        first = ' '.join([str(x) for x in self.true])\n",
    "        second = ' '.join([str(x) for x in self.pred])\n",
    "        return f'({first}, {second})'\n",
    "\n",
    "@dataclass\n",
    "class MatchesList:\n",
    "    matches: list[Match]\n",
    "    total_true_len: int\n",
    "    total_n_errs: int\n",
    "    total_n_correct: int\n",
    "    \n",
    "    @classmethod\n",
    "    def from_list(cls, matches: list[Match]) -> MatchesList:\n",
    "        return MatchesList(\n",
    "            matches=matches,\n",
    "            total_true_len=sum(m.true_len for m in matches),\n",
    "            total_n_errs=sum(m.n_errs for m in matches),\n",
    "            total_n_correct=sum(m.n_errs == 0 for m in matches),\n",
    "        )\n",
    "    \n",
    "    def prepend(self, match: Match) -> MatchesList:\n",
    "        return MatchesList(\n",
    "            matches=[match] + self.matches,\n",
    "            total_true_len=match.true_len + self.total_true_len,\n",
    "            total_n_errs=match.n_errs + self.total_n_errs,\n",
    "            total_n_correct=(match.n_errs == 0) + self.total_n_correct,\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def value(self) -> int:\n",
    "        return self.total_n_errs * 1_000_000 - self.total_n_correct\n",
    "    \n",
    "\n",
    "def select_shortest_multi_variants(seq: list[Token | MultiVariant]) -> list[Token]:\n",
    "    result: list[Token] = []\n",
    "    for x in seq:\n",
    "        if isinstance(x, MultiVariant):\n",
    "            result += min(x.options, key=len)\n",
    "        else:\n",
    "            result.append(x)\n",
    "    return result\n",
    "\n",
    "def align(\n",
    "    true: list[Token | MultiVariant],\n",
    "    pred: list[Token],\n",
    "    try_speedup: bool = False,\n",
    ") -> MatchesList:\n",
    "    multivariant_prefixes: dict[tuple[str, int], list[Token]] = {}\n",
    "    for x in true:\n",
    "        if isinstance(x, MultiVariant):\n",
    "            for i, option in enumerate(x.options):\n",
    "                multivariant_prefixes[x.uid, i] = option\n",
    "    \n",
    "    err_cap = np.inf\n",
    "    if len(true) > 50 and len(pred) > 50 and try_speedup:\n",
    "        # block-wise\n",
    "        n_blocks = 10\n",
    "        true_points = np.linspace(0, len(true), num=n_blocks + 1, endpoint=True, dtype=int)\n",
    "        pred_points = np.linspace(0, len(pred), num=n_blocks + 1, endpoint=True, dtype=int)\n",
    "        matches_per_block: list[MatchesList] = []\n",
    "        for i in range(n_blocks):\n",
    "            matches_per_block.append(align(\n",
    "                true[true_points[i]:true_points[i + 1]],\n",
    "                pred[pred_points[i]:pred_points[i + 1]],\n",
    "            ))\n",
    "        err_cap = sum([m.total_n_errs for m in matches_per_block])\n",
    "        print('err_cap', err_cap)\n",
    "    \n",
    "    @cached(cache={}, key=lambda *args: hashkey(*args[:-1]), info=True)  # do not cache the last argument\n",
    "    def _align_recursive(\n",
    "        true_pos: int,\n",
    "        pred_pos: int,\n",
    "        multivariant_prefix_id: tuple[str, int] | None,\n",
    "        multivariant_prefix_pos: int,\n",
    "        prev_total_err: int,\n",
    "    ) -> MatchesList:\n",
    "        # print('call', true_pos, pred_pos, multivariant_prefix_idx, multivariant_prefix_pos)\n",
    "        _true = true[true_pos:]\n",
    "        _pred = pred[pred_pos:]\n",
    "        \n",
    "        if multivariant_prefix_id is not None:\n",
    "            prefix = multivariant_prefixes[multivariant_prefix_id][multivariant_prefix_pos:]\n",
    "            _true = prefix + _true\n",
    "        \n",
    "        if len(_pred) == 0 and len(_true) == 0:\n",
    "            return MatchesList.from_list([])\n",
    "        elif len(_pred) == 0 and len(_true) > 0:\n",
    "            _matches: list[Match] = []\n",
    "            for token in _true:\n",
    "                if len(shortest := select_shortest_multi_variants([token])):\n",
    "                    _matches.append(Match.from_pair(shortest, []))\n",
    "            return MatchesList.from_list(_matches)\n",
    "        elif len(_pred) > 0 and len(_true) == 0:\n",
    "            return MatchesList.from_list([\n",
    "                Match.from_pair([], [token])\n",
    "                for token in _pred\n",
    "            ])\n",
    "        elif not isinstance(_true[0], MultiVariant):\n",
    "            options: list[MatchesList] = []\n",
    "            current_match_options = [\n",
    "                # option 1: match true[0] with pred[0]\n",
    "                (1, 1, Match.from_pair(_true[:1], _pred[:1])), # type: ignore\n",
    "                # option 2: match pred[0] with nothing\n",
    "                (0, 1, Match.from_pair([], _pred[:1])),\n",
    "                # option 3: match true[0] with nothing\n",
    "                (1, 0, Match.from_pair(_true[:1], [])), # type: ignore\n",
    "            ]\n",
    "            filtered_match_options = [\n",
    "                (i, j, current_match)\n",
    "                for i, j, current_match in current_match_options\n",
    "                if prev_total_err + current_match.n_errs <= err_cap\n",
    "            ]\n",
    "            if len(filtered_match_options) == 0:\n",
    "                filtered_match_options = current_match_options[:1]\n",
    "            for i, j, current_match in filtered_match_options:\n",
    "                new_true_pos = true_pos\n",
    "                new_multivariant_prefix_idx = multivariant_prefix_id\n",
    "                new_multivariant_prefix_pos = multivariant_prefix_pos\n",
    "                if i == 1:\n",
    "                    if multivariant_prefix_id is not None:\n",
    "                        if len(prefix) > 1: # type: ignore\n",
    "                            new_multivariant_prefix_pos += 1\n",
    "                        else:\n",
    "                            new_multivariant_prefix_idx = None\n",
    "                            new_multivariant_prefix_pos = 0\n",
    "                    else:\n",
    "                        new_true_pos += 1\n",
    "                _results = _align_recursive(\n",
    "                        new_true_pos,\n",
    "                        pred_pos + j,\n",
    "                        new_multivariant_prefix_idx,\n",
    "                        new_multivariant_prefix_pos,\n",
    "                        prev_total_err + current_match.n_errs\n",
    "                    )\n",
    "                options.append(\n",
    "                    _results.prepend(current_match)\n",
    "                )\n",
    "            if isinstance(_true[0].value, Anything):\n",
    "                current_match = Match.from_pair(_true[:1], _pred[:1]) # type: ignore\n",
    "                options.append(\n",
    "                    # option 4: match Anything with pred[0], but keep Anything in the true tokens\n",
    "                    _align_recursive(\n",
    "                        true_pos,\n",
    "                        pred_pos + 1,\n",
    "                        multivariant_prefix_id,\n",
    "                        multivariant_prefix_pos,\n",
    "                        prev_total_err,\n",
    "                    ).prepend(current_match)\n",
    "                )\n",
    "            # print('_true', _true)\n",
    "            # print('_pred', _pred)\n",
    "            # print('OPTIONS')\n",
    "            # for opt in options:\n",
    "            #     print(opt.value, opt)\n",
    "            \n",
    "            return min(options, key=lambda x: x.value)\n",
    "        else:\n",
    "            assert multivariant_prefix_id is None\n",
    "            options = [\n",
    "                _align_recursive(\n",
    "                    true_pos + 1,\n",
    "                    pred_pos,\n",
    "                    (_true[0].uid, i),\n",
    "                    0,\n",
    "                    prev_total_err,\n",
    "                )\n",
    "                for i in range(len(_true[0].options))\n",
    "            ]\n",
    "            return min(options, key=lambda x: x.value)\n",
    "    \n",
    "    result = _align_recursive(0, 0, None, 0, 0)\n",
    "    print(_align_recursive.cache_info()) # type: ignore\n",
    "    return result\n",
    "\n",
    "# matches_list = align(\n",
    "#     [\n",
    "#         Token(Anything()),\n",
    "#     ],\n",
    "#     tokens_from_text('a b')\n",
    "# )\n",
    "\n",
    "# matches_list = align(\n",
    "#     [\n",
    "#         Token(Anything()),\n",
    "#         multi_variant_from_texts(['a b', 'a']),\n",
    "#         multi_variant_from_texts(['a', 'b a']),\n",
    "#         multi_variant_from_texts(['x', 'y']),\n",
    "#     ],\n",
    "#     tokens_from_text('a b a')\n",
    "# )\n",
    "\n",
    "# matches_list = align(\n",
    "#     [\n",
    "#         multi_variant_from_texts(['a']),\n",
    "#         Token('x'),\n",
    "#     ],\n",
    "#     [Token('a')],\n",
    "# )\n",
    "\n",
    "# matches_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CacheInfo(hits=20000, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20200, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20400, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20700, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20500, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20000, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20100, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20300, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=20400, misses=10201, maxsize=None, currsize=10201)\n",
      "CacheInfo(hits=19900, misses=10201, maxsize=None, currsize=10201)\n",
      "err_cap 258\n",
      "CacheInfo(hits=352297, misses=706962, maxsize=None, currsize=706962)\n",
      "CPU times: user 29.2 s, sys: 138 ms, total: 29.3 s\n",
      "Wall time: 29.3 s\n",
      "errs 270\n"
     ]
    }
   ],
   "source": [
    "true = [Token(str(x)) if np.random.rand() > 0.05 else Token(Anything()) for x in np.random.randint(0, 2, size=1000)]\n",
    "pred = [Token(str(x)) for x in np.random.randint(0, 2, size=1000)]\n",
    "\n",
    "%time result = align(true, pred, try_speedup=True) # type: ignore\n",
    "\n",
    "print('errs', result.total_n_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854 831\n",
      "CacheInfo(hits=1450072, misses=711360, maxsize=None, currsize=711360)\n",
      "CPU times: user 52 s, sys: 177 ms, total: 52.2 s\n",
      "Wall time: 52.2 s\n",
      "errs 712\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df  = pd.read_csv('../eval_common_voice_17_0test_200samples.csv', skiprows=1) # type: ignore\n",
    "true = [\n",
    "    Token(word) if np.random.rand() > 0.05 else Token(Anything())\n",
    "    for word in ' '.join(df.iloc[:100]['true_texts']).split() # type: ignore\n",
    "]\n",
    "pred = [\n",
    "    Token(word)\n",
    "    for word in ' '.join(df.iloc[:100]['pred_texts']).split() # type: ignore\n",
    "]\n",
    "print(len(true), len(pred))\n",
    "\n",
    "%time result = align(true, pred, try_speedup=False) # type: ignore\n",
    "print('errs', result.total_n_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CacheInfo(hits=14274, misses=7224, maxsize=None, currsize=7224)\n",
      "CacheInfo(hits=14357, misses=7224, maxsize=None, currsize=7224)\n",
      "CacheInfo(hits=14522, misses=7308, maxsize=None, currsize=7308)\n",
      "CacheInfo(hits=14108, misses=7224, maxsize=None, currsize=7224)\n",
      "CacheInfo(hits=14522, misses=7308, maxsize=None, currsize=7308)\n",
      "CacheInfo(hits=14357, misses=7224, maxsize=None, currsize=7224)\n",
      "CacheInfo(hits=14108, misses=7224, maxsize=None, currsize=7224)\n",
      "CacheInfo(hits=14439, misses=7308, maxsize=None, currsize=7308)\n",
      "CacheInfo(hits=14357, misses=7224, maxsize=None, currsize=7224)\n",
      "CacheInfo(hits=14446, misses=7395, maxsize=None, currsize=7395)\n",
      "err_cap 735\n",
      "CacheInfo(hits=1212441, misses=706304, maxsize=None, currsize=706304)\n",
      "CPU times: user 47 s, sys: 205 ms, total: 47.2 s\n",
      "Wall time: 47.2 s\n",
      "errs 717\n"
     ]
    }
   ],
   "source": [
    "%time result = align(true, pred, try_speedup=True) # type: ignore\n",
    "print('errs', result.total_n_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
